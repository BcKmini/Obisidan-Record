## Cat&Dog ì´ì •ë¦¬
# ğŸ§  CNNì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµí•˜ê¸° â€“ PyTorchë¡œ êµ¬í˜„  
ì´ë²ˆ ê¸€ì—ì„œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ **ê°•ì•„ì§€ ğŸ¶ vs. ê³ ì–‘ì´ ğŸ± ì „ì²˜ë¦¬,  ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ê³  í•™ìŠµí•˜ëŠ” ê³¼ì •

---
## ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ 
```python 
import torch 
import torchvision 
import torch.nn as nn 
import torch.optim as optim from torchvision 
import transforms from torch.utils.data 
import DataLoader, random_split from torchvision.datasets
import ImageFolder 
import matplotlib.pyplot as plt import numpy as np
```

 - **ì‚¬ìš©ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬**
   - `torchvision.transforms` â†’ ì´ë¯¸ì§€ ë³€í™˜(Resize, Tensor ë³€í™˜ ë“±)
   - `ImageFolder` â†’ í´ë”ì— ì €ì¥ëœ ì´ë¯¸ì§€ë¥¼ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¡œë“œ
   - `DataLoader` â†’ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
   - `random_split` â†’ ë°ì´í„°ë¥¼ **í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• **
   - `matplotlib.pyplot` â†’ ë°ì´í„° ì‹œê°í™”

---

## ğŸ“Œ 2. ë°ì´í„° ì „ì²˜ë¦¬ (ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • & í…ì„œ ë³€í™˜)
```python
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 64x64 í¬ê¸°ë¡œ ë³€í™˜
    transforms.ToTensor(),        # PyTorch í…ì„œë¡œ ë³€í™˜
])
```
- **ì „ì²˜ë¦¬ ê³¼ì •**  
  - `Resize((64, 64))` â†’ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ **ê³ ì • í¬ê¸°(64x64)**ë¡œ ë³€í™˜  
  - `ToTensor()` â†’ ì´ë¯¸ì§€ë¥¼ **PyTorch í…ì„œ**ë¡œ ë³€í™˜ (í”½ì…€ê°’ì„ [0,1] ë²”ìœ„ë¡œ ì •ê·œí™”)
  
> ëª¨ë¸ì´ ì…ë ¥ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ **ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜**

---
## ğŸ“Œ 3. ë°ì´í„°ì…‹ ë¡œë“œ (ImageFolder í™œìš©)
```python
dataset = ImageFolder(root='../Dog_Cat/dataset', transform=transform)
print(f"Total samples: {len(dataset)}")
```
- ImageFolderëŠ” í´ë” êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ë¼ë²¨ë§í•´ì£¼ëŠ” ë°ì´í„°ì…‹ ë¡œë”
  - `root='../Dog_Cat/dataset'` â†’ ë°ì´í„°ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
  - `transform=transform` â†’ ì•ì—ì„œ ì •ì˜í•œ **ì „ì²˜ë¦¬(transform)** ì ìš©
  
>`dataset.classes`ë¥¼ ì¶œë ¥í•˜ë©´ **í´ë˜ìŠ¤ ì´ë¦„(ê°•ì•„ì§€, ê³ ì–‘ì´ ë“±)ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¨ë‹¤.**


---
## ğŸ“Œ 4. ë°ì´í„°ì…‹ ë¶„í•  (Train, Validation, Test)
```python
# ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸
train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])

# ë°ì´í„°ì…‹ í¬ê¸° ì¶œë ¥
print(f"Number of training samples: {len(train_data)}")
print(f"Number of validation samples: {len(val_data)}")
print(f"Number of testing samples: {len(test_data)}")
```
ğŸ“Œ **ë°ì´í„°ì…‹ ë¶„í•  ë¹„ìœ¨**
- **80%** â†’ í•™ìŠµ ë°ì´í„°(train)
- **10%** â†’ ê²€ì¦ ë°ì´í„°(validation)
- **10%** â†’ í…ŒìŠ¤íŠ¸ ë°ì´í„°(test)

> `random_split`ì„ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ë¥¼ ëœë¤í•˜ê²Œ ë¶„í•  ê°€ëŠ¥

---
## ğŸ“Œ 5. ë°ì´í„° ë¡œë” ìƒì„± (Batch ë‹¨ìœ„ ë¡œë”©)
```python
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)
```
- `DataLoader`ë¥¼ ì‚¬ìš©í•˜ë©´ **ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.**
  - `batch_size=32` â†’ í•œ ë²ˆì— **32ê°œ ì´ë¯¸ì§€**ì”© ë¶ˆëŸ¬ì˜´
  - `shuffle=True` â†’ **í›ˆë ¨ ë°ì´í„°ëŠ” ëœë¤í•˜ê²Œ ì„ìŒ**
  - `shuffle=False` â†’ ê²€ì¦ & í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ê³ ì •ëœ ìˆœì„œ ìœ ì§€

 >ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ê²½ìš°, í•œ ë²ˆì— ë¡œë“œí•˜ëŠ” ê²ƒì´ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ **ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬**í•œë‹¤.
---
## ğŸ“Œ 6. í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸ (ìë™ ë¼ë²¨ë§ í™•ì¸)
```python
print(f"Classes: {dataset.classes}")

# dataset.classesëŠ” **í´ë” ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ í´ë˜ìŠ¤ ë¼ë²¨ì„ ê°€ì ¸ì˜¨ë‹¤.**  

#ì˜ˆë¥¼ ë“¤ì–´, `dataset` í´ë” êµ¬ì¡°ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤ë©´:
../Dog_Cat/dataset/
â”œâ”€â”€ cat/
â”‚   â”œâ”€â”€ cat1.jpg
â”‚   â”œâ”€â”€ cat2.jpg
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ dog/
â”‚   â”œâ”€â”€ dog1.jpg
â”‚   â”œâ”€â”€ dog2.jpg
â”‚   â”œâ”€â”€ ...

# dataset.clases ì¶œë ¥ ê²°ê³¼
['cat', 'dog']
```
---
## ğŸ“Œ 7. ë°ì´í„° í™•ì¸ (ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”)
```python
def imshow(img):
    img = img / 2 + 0.5  # ì •ê·œí™” í•´ì œ (PyTorchëŠ” [0,1] ë²”ìœ„ë¡œ ë³€í™˜ë¨)
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # (C, H, W) â†’ (H, W, C)
    plt.show()

# ë°ì´í„° ë¡œë”ì—ì„œ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
dataiter = iter(train_loader)
images, labels = next(dataiter)

# ì²« 4ê°œ ì´ë¯¸ì§€ ì¶œë ¥
imshow(torchvision.utils.make_grid(images[:4]))
```

-  **ì´ë¯¸ì§€ ì‹œê°í™” ê³¼ì •**  
  - `make_grid()` â†’ **ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¡œ ì •ë ¬**  
  - `np.transpose()` â†’ **PyTorch ì´ë¯¸ì§€ í˜•ì‹(C, H, W)ì„ ì¼ë°˜ ì´ë¯¸ì§€ í˜•ì‹(H, W, C)ë¡œ ë³€í™˜**  
  - `plt.imshow()` â†’ ìµœì¢…ì ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶œë ¥

>ì‹¤í–‰í•˜ë©´ ëœë¤í•˜ê²Œ ì„ íƒëœ 4ê°œì˜ í•™ìŠµ ë°ì´í„° ì´ë¯¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---
## ğŸ“Œ 8. CNN ëª¨ë¸ ì •ì˜
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 16 * 16, 128)
        self.fc2 = nn.Linear(128, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 32 * 16 * 16)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
        

```
-  **CNNì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ**  
  - `Conv2d` â†’ ì´ë¯¸ì§€ì—ì„œ **íŠ¹ì§•ì„ ì¶”ì¶œ**í•˜ëŠ” í•©ì„±ê³± ê³„ì¸µ  
  - `ReLU` â†’ ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ í‘œí˜„ë ¥ì„ ë†’ì„  
  - `-MaxPool2d` â†’ ë‹¤ìš´ìƒ˜í”Œë§ì„ í†µí•´ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê³  íŠ¹ì§•ì„ ë” ìš”ì•½  
 - `Linear` â†’ **ì™„ì „ ì—°ê²°ì¸µ (FC Layer)**, ìµœì¢…ì ì¸ ë¶„ë¥˜ ìˆ˜í–‰

>ì…ë ¥ ì´ë¯¸ì§€ëŠ” **3ì±„ë„(RGB), í¬ê¸° 32x32ë¡œ ê°€ì •**  
>ë§ˆì§€ë§‰ `fc2` ì¸µì—ì„œ **ì¶œë ¥ ë…¸ë“œ ìˆ˜ = 2 (ê°•ì•„ì§€ vs ê³ ì–‘ì´ ë¶„ë¥˜)**

---
## ğŸ“Œ 9. ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì •ì˜
```python
import torch.optim as optim

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

```
- **ì†ì‹¤ í•¨ìˆ˜ & ìµœì í™” í•¨ìˆ˜ ì„ íƒ**
  - `CrossEntropyLoss()` â†’ **ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œ**ì—ì„œ ì‚¬ìš©
  - `Adam` â†’ Adaptive Momentumì„ í™œìš©í•˜ëŠ” **ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜**
  - `lr=0.001` â†’ í•™ìŠµë¥  ì„¤ì • (ë„ˆë¬´ í¬ë©´ ë°œì‚°, ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµ ì†ë„ê°€ ëŠë¦¼)

>ëª¨ë¸ì„ **GPU/CPUë¡œ ì´ë™**ì‹œì¼œ í•™ìŠµì„ ì¤€ë¹„

---
## ğŸ“Œ 10. ëª¨ë¸ í•™ìŠµ ê³¼ì • (Training)
```python
num_epochs = 20
for epoch in range(num_epochs):
    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
    running_loss = 0.0
    
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()  # ê¸°ì¡´ì˜ ê¸°ìš¸ê¸° ì´ˆê¸°í™”

        outputs = model(inputs)  # ìˆœì „íŒŒ (Forward Propagation)
        loss = criterion(outputs, labels)  # ì†ì‹¤ ê³„ì‚°
        loss.backward()  # ì—­ì „íŒŒ (Backward Propagation)
        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")
```

 - **ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì • ì •ë¦¬**  
  - **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°** (`train_loader`)  
   - **ìˆœì „íŒŒ(Forward Propagation)**: ì…ë ¥ ë°ì´í„°ë¥¼ CNN ëª¨ë¸ì— í†µê³¼  
   - **ì†ì‹¤(loss) ê³„ì‚°**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ë¼ë²¨ ë¹„êµ  
   - **ì—­ì „íŒŒ(Backward Propagation)**: ì†ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ **ê¸°ìš¸ê¸° ê³„ì‚°**  
   - **ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸** (`optimizer.step()`)  
   - ë°˜ë³µí•˜ì—¬ **ì—í¬í¬(epoch) ë‹¨ìœ„ë¡œ ëª¨ë¸ í•™ìŠµ**
```python
`print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")`  
```
ë§¤ Epochë§ˆë‹¤ í‰ê·  ì†ì‹¤ì„ ì¶œë ¥í•˜ì—¬ í•™ìŠµì´ ì˜ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸

---
## ğŸ“Œ 11. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (Test)
```python
model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
correct = 0
total = 0

with torch.no_grad():  # í‰ê°€ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy: {100 * correct / total:.2f}%")
```
- **ëª¨ë¸ í‰ê°€ ê³¼ì •**  
   - `model.eval()` â†’ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • (BatchNorm, Dropout ë¹„í™œì„±í™”)  
   - `torch.no_grad()` â†’ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•˜ì—¬ **ë©”ëª¨ë¦¬ ì ˆì•½ & ì†ë„ ì¦ê°€**  
   - `torch.max(outputs.data, 1)` â†’ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì„ íƒ  
   -  `Accuracy` ê³„ì‚°í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •

>`print(f"Accuracy: {100 * correct / total:.2f}%")`  
>ì •í™•ë„ë¥¼ í¼ì„¼íŠ¸(%) ë‹¨ìœ„ë¡œ ì¶œë ¥í•˜ì—¬ ìµœì¢… ì„±ëŠ¥ì„ í™•ì¸

---


## ğŸš€ **ë‹¤ìŒ ë‹¨ê³„**
ë°ì´í„° ì¦ê°•(Data Augmentation)
ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± (ResNet, VGG ë“± í™œìš©)
í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (learning rate, batch size ë“± ì¡°ì •)

> ì°¸ê³  : [Github](https://github.com/BcKmini/Obisidan-Blog) - í•™ë¶€ì—°êµ¬ìƒ/Code/Dog_Cat
