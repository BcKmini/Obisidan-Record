## Cat&Dog 총정리
# 🧠 CNN을 활용한 이미지 분류 모델 학습하기 – PyTorch로 구현  
이번 글에서는 PyTorch를 사용하여 **강아지 🐶 vs. 고양이 🐱 전처리,  분류 모델을 구현하고 학습하는 과정

---
## 📌 1. 필요한 라이브러리 임포트 
```python 
import torch 
import torchvision 
import torch.nn as nn 
import torch.optim as optim from torchvision 
import transforms from torch.utils.data 
import DataLoader, random_split from torchvision.datasets
import ImageFolder 
import matplotlib.pyplot as plt import numpy as np
```

 - **사용된 라이브러리**
   - `torchvision.transforms` → 이미지 변환(Resize, Tensor 변환 등)
   - `ImageFolder` → 폴더에 저장된 이미지를 데이터셋으로 로드
   - `DataLoader` → 배치 단위로 데이터를 로드하는 함수
   - `random_split` → 데이터를 **학습/검증/테스트 세트로 분할**
   - `matplotlib.pyplot` → 데이터 시각화

---

## 📌 2. 데이터 전처리 (이미지 크기 조정 & 텐서 변환)
```python
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # 모든 이미지를 64x64 크기로 변환
    transforms.ToTensor(),        # PyTorch 텐서로 변환
])
```
- **전처리 과정**  
  - `Resize((64, 64))` → 모든 이미지를 **고정 크기(64x64)**로 변환  
  - `ToTensor()` → 이미지를 **PyTorch 텐서**로 변환 (픽셀값을 [0,1] 범위로 정규화)
  
> 모델이 입력을 받을 수 있도록 **일관된 형식으로 변환**

---
## 📌 3. 데이터셋 로드 (ImageFolder 활용)
```python
dataset = ImageFolder(root='../Dog_Cat/dataset', transform=transform)
print(f"Total samples: {len(dataset)}")
```
- ImageFolder는 폴더 구조를 자동으로 라벨링해주는 데이터셋 로더
  - `root='../Dog_Cat/dataset'` → 데이터가 있는 폴더 경로
  - `transform=transform` → 앞에서 정의한 **전처리(transform)** 적용
  
>`dataset.classes`를 출력하면 **클래스 이름(강아지, 고양이 등)을 자동으로 가져온다.**


---
## 📌 4. 데이터셋 분할 (Train, Validation, Test)
```python
# 데이터셋 크기 확인
train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])

# 데이터셋 크기 출력
print(f"Number of training samples: {len(train_data)}")
print(f"Number of validation samples: {len(val_data)}")
print(f"Number of testing samples: {len(test_data)}")
```
📌 **데이터셋 분할 비율**
- **80%** → 학습 데이터(train)
- **10%** → 검증 데이터(validation)
- **10%** → 테스트 데이터(test)

> `random_split`을 사용하면 데이터를 랜덤하게 분할 가능

---
## 📌 5. 데이터 로더 생성 (Batch 단위 로딩)
```python
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)
```
- `DataLoader`를 사용하면 **미니배치 단위로 데이터를 불러올 수 있다.**
  - `batch_size=32` → 한 번에 **32개 이미지**씩 불러옴
  - `shuffle=True` → **훈련 데이터는 랜덤하게 섞음**
  - `shuffle=False` → 검증 & 테스트 데이터는 고정된 순서 유지

 >데이터가 너무 많을 경우, 한 번에 로드하는 것이 비효율적이므로 **미니배치로 나눠서 처리**한다.
---
## 📌 6. 클래스 이름 확인 (자동 라벨링 확인)
```python
print(f"Classes: {dataset.classes}")

# dataset.classes는 **폴더 이름을 기반으로 자동으로 클래스 라벨을 가져온다.**  

#예를 들어, `dataset` 폴더 구조가 다음과 같다면:
../Dog_Cat/dataset/
├── cat/
│   ├── cat1.jpg
│   ├── cat2.jpg
│   ├── ...
├── dog/
│   ├── dog1.jpg
│   ├── dog2.jpg
│   ├── ...

# dataset.clases 출력 결과
['cat', 'dog']
```
---
## 📌 7. 데이터 확인 (샘플 이미지 시각화)
```python
def imshow(img):
    img = img / 2 + 0.5  # 정규화 해제 (PyTorch는 [0,1] 범위로 변환됨)
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # (C, H, W) → (H, W, C)
    plt.show()

# 데이터 로더에서 샘플 가져오기
dataiter = iter(train_loader)
images, labels = next(dataiter)

# 첫 4개 이미지 출력
imshow(torchvision.utils.make_grid(images[:4]))
```

-  **이미지 시각화 과정**  
  - `make_grid()` → **여러 개의 이미지를 하나의 이미지로 정렬**  
  - `np.transpose()` → **PyTorch 이미지 형식(C, H, W)을 일반 이미지 형식(H, W, C)로 변환**  
  - `plt.imshow()` → 최종적으로 이미지 출력

>실행하면 랜덤하게 선택된 4개의 학습 데이터 이미지를 확인할 수 있다.

---
## 📌 8. CNN 모델 정의
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 16 * 16, 128)
        self.fc2 = nn.Linear(128, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 32 * 16 * 16)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
        

```
-  **CNN의 주요 구성 요소**  
  - `Conv2d` → 이미지에서 **특징을 추출**하는 합성곱 계층  
  - `ReLU` → 비선형성을 추가하여 모델의 표현력을 높임  
  - `-MaxPool2d` → 다운샘플링을 통해 계산량을 줄이고 특징을 더 요약  
 - `Linear` → **완전 연결층 (FC Layer)**, 최종적인 분류 수행

>입력 이미지는 **3채널(RGB), 크기 32x32로 가정**  
>마지막 `fc2` 층에서 **출력 노드 수 = 2 (강아지 vs 고양이 분류)**

---
## 📌 9. 손실 함수 및 최적화 함수 정의
```python
import torch.optim as optim

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

```
- **손실 함수 & 최적화 함수 선택**
  - `CrossEntropyLoss()` → **다중 클래스 분류 문제**에서 사용
  - `Adam` → Adaptive Momentum을 활용하는 **가장 널리 쓰이는 최적화 알고리즘**
  - `lr=0.001` → 학습률 설정 (너무 크면 발산, 너무 작으면 학습 속도가 느림)

>모델을 **GPU/CPU로 이동**시켜 학습을 준비

---
## 📌 10. 모델 학습 과정 (Training)
```python
num_epochs = 20
for epoch in range(num_epochs):
    model.train()  # 모델을 학습 모드로 설정
    running_loss = 0.0
    
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()  # 기존의 기울기 초기화

        outputs = model(inputs)  # 순전파 (Forward Propagation)
        loss = criterion(outputs, labels)  # 손실 계산
        loss.backward()  # 역전파 (Backward Propagation)
        optimizer.step()  # 가중치 업데이트

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")
```

 - **딥러닝 학습 과정 정리**  
  - **데이터 불러오기** (`train_loader`)  
   - **순전파(Forward Propagation)**: 입력 데이터를 CNN 모델에 통과  
   - **손실(loss) 계산**: 예측값과 실제 라벨 비교  
   - **역전파(Backward Propagation)**: 손실을 기반으로 **기울기 계산**  
   - **가중치 업데이트** (`optimizer.step()`)  
   - 반복하여 **에포크(epoch) 단위로 모델 학습**
```python
`print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")`  
```
매 Epoch마다 평균 손실을 출력하여 학습이 잘 되고 있는지 확인

---
## 📌 11. 모델 성능 평가 (Test)
```python
model.eval()  # 모델을 평가 모드로 설정
correct = 0
total = 0

with torch.no_grad():  # 평가 시에는 그래디언트 계산 비활성화 (속도 최적화)
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy: {100 * correct / total:.2f}%")
```
- **모델 평가 과정**  
   - `model.eval()` → 모델을 평가 모드로 설정 (BatchNorm, Dropout 비활성화)  
   - `torch.no_grad()` → 그래디언트 계산을 비활성화하여 **메모리 절약 & 속도 증가**  
   - `torch.max(outputs.data, 1)` → 가장 높은 확률을 가진 클래스를 예측값으로 선택  
   -  `Accuracy` 계산하여 모델의 성능을 측정

>`print(f"Accuracy: {100 * correct / total:.2f}%")`  
>정확도를 퍼센트(%) 단위로 출력하여 최종 성능을 확인

---


## 🚀 **다음 단계**
데이터 증강(Data Augmentation)
더 깊은 네트워크 구성 (ResNet, VGG 등 활용)
하이퍼파라미터 튜닝 (learning rate, batch size 등 조정)

> 참고 : [Github](https://github.com/BcKmini/Obisidan-Blog) - 학부연구생/Code/Dog_Cat
