## Cat&Dog 총정리
# 🧠 CNN을 활용한 이미지 분류 모델 학습하기 – PyTorch로 구현  
이번 글에서는 PyTorch를 사용하여 **강아지 🐶 vs. 고양이 🐱 전처리,  분류 모델을 구현하고 학습하는 과정



---

## 📌 1. 필요한 라이브러리 임포트
```python
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
import matplotlib.pyplot as plt
import numpy as np


---
## 📌 1. 학습을 수행할 디바이스 설정 (CPU vs GPU)
```python
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

👉 현재 사용 가능한 **연산 디바이스(GPU 또는 CPU)를 자동 선택**한다.  
👉 **GPU가 있다면 `cuda`를 사용**, 없으면 `cpu`에서 연산한다.  
👉 이는 **대량의 행렬 연산을 수행하는 딥러닝 모델에서 필수적인 코드**이다.
```

---

📌 2. CNN 모델 정의
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 16 * 16, 128)
        self.fc2 = nn.Linear(128, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 32 * 16 * 16)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
        
📌 **CNN의 주요 구성 요소**  
1️⃣ `Conv2d` → 이미지에서 **특징을 추출**하는 합성곱 계층  
2️⃣ `ReLU` → 비선형성을 추가하여 모델의 표현력을 높임  
3️⃣ `MaxPool2d` → 다운샘플링을 통해 계산량을 줄이고 특징을 더 요약  
4️⃣ `Linear` → **완전 연결층 (FC Layer)**, 최종적인 분류 수행

👉 입력 이미지는 **3채널(RGB), 크기 32x32로 가정**  
👉 마지막 `fc2` 층에서 **출력 노드 수 = 2 (강아지 vs 고양이 분류)**
```

📌 3. 손실 함수 및 최적화 함수 정의
```python
import torch.optim as optim

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

📌 **손실 함수 & 최적화 함수 선택**

- `CrossEntropyLoss()` → **다중 클래스 분류 문제**에서 사용
- `Adam` → Adaptive Momentum을 활용하는 **가장 널리 쓰이는 최적화 알고리즘**
- `lr=0.001` → 학습률 설정 (너무 크면 발산, 너무 작으면 학습 속도가 느림)

👉 모델을 **GPU/CPU로 이동**시켜 학습을 준비한다.
```

---
📌 4. 모델 학습 과정 (Training)
```python
num_epochs = 20
for epoch in range(num_epochs):
    model.train()  # 모델을 학습 모드로 설정
    running_loss = 0.0
    
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()  # 기존의 기울기 초기화

        outputs = model(inputs)  # 순전파 (Forward Propagation)
        loss = criterion(outputs, labels)  # 손실 계산
        loss.backward()  # 역전파 (Backward Propagation)
        optimizer.step()  # 가중치 업데이트

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")

📌 **딥러닝 학습 과정 정리**  
1️⃣ **데이터 불러오기** (`train_loader`)  
2️⃣ **순전파(Forward Propagation)**: 입력 데이터를 CNN 모델에 통과  
3️⃣ **손실(loss) 계산**: 예측값과 실제 라벨 비교  
4️⃣ **역전파(Backward Propagation)**: 손실을 기반으로 **기울기 계산**  
5️⃣ **가중치 업데이트** (`optimizer.step()`)  
6️⃣ 반복하여 **에포크(epoch) 단위로 모델 학습**

👉 `print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")`  
👉 매 Epoch마다 평균 손실을 출력하여 학습이 잘 되고 있는지 확인한다.
```

---
📌 5. 모델 성능 평가 (Test)
```python
model.eval()  # 모델을 평가 모드로 설정
correct = 0
total = 0

with torch.no_grad():  # 평가 시에는 그래디언트 계산 비활성화 (속도 최적화)
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy: {100 * correct / total:.2f}%")

📌 **모델 평가 과정**  
1️⃣ `model.eval()` → 모델을 평가 모드로 설정 (BatchNorm, Dropout 비활성화)  
2️⃣ `torch.no_grad()` → 그래디언트 계산을 비활성화하여 **메모리 절약 & 속도 증가**  
3️⃣ `torch.max(outputs.data, 1)` → 가장 높은 확률을 가진 클래스를 예측값으로 선택  
4️⃣ `Accuracy` 계산하여 모델의 성능을 측정

👉 `print(f"Accuracy: {100 * correct / total:.2f}%")`  
👉 정확도를 퍼센트(%) 단위로 출력하여 **최종 성능을 확**
```

## 🎯 **정리**

✅ CNN을 활용한 **이미지 분류 모델(SimpleCNN) 구현**  
✅ **손실 함수(CrossEntropyLoss)와 최적화 함수(Adam) 설정**  
✅ 데이터셋을 활용하여 **모델 학습(Training) 진행**  
✅ 학습 완료 후 **모델의 성능 평가(Test) 수행**

---

## 🚀 **다음 단계**

이제 기본적인 CNN 모델을 학습하는 방법을 익혔다.  
다음 단계에서는 **모델의 정확도를 높이기 위해 아래 방법을 고려해볼 수 있다.**

✅ **데이터 증강(Data Augmentation)**  
✅ **더 깊은 네트워크 구성 (ResNet, VGG 등 활용)**  
✅ **하이퍼파라미터 튜닝 (learning rate, batch size 등 조정)**

이제 직접 구현하고, 모델을 개선해보자! 😆🔥  
궁금한 점이 있다면 댓글 남겨주세요. 😊