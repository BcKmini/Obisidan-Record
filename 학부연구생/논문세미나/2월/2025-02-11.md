## Cat&Dog ì´ì •ë¦¬
# ğŸ§  CNNì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµí•˜ê¸° â€“ PyTorchë¡œ êµ¬í˜„  
ì´ë²ˆ ê¸€ì—ì„œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ **ê°•ì•„ì§€ ğŸ¶ vs. ê³ ì–‘ì´ ğŸ± ì „ì²˜ë¦¬,  ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ê³  í•™ìŠµí•˜ëŠ” ê³¼ì •



---

## ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
```python
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
import matplotlib.pyplot as plt
import numpy as np


---
## ğŸ“Œ 1. í•™ìŠµì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤ ì„¤ì • (CPU vs GPU)
```python
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

ğŸ‘‰ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ **ì—°ì‚° ë””ë°”ì´ìŠ¤(GPU ë˜ëŠ” CPU)ë¥¼ ìë™ ì„ íƒ**í•œë‹¤.  
ğŸ‘‰ **GPUê°€ ìˆë‹¤ë©´ `cuda`ë¥¼ ì‚¬ìš©**, ì—†ìœ¼ë©´ `cpu`ì—ì„œ ì—°ì‚°í•œë‹¤.  
ğŸ‘‰ ì´ëŠ” **ëŒ€ëŸ‰ì˜ í–‰ë ¬ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ í•„ìˆ˜ì ì¸ ì½”ë“œ**ì´ë‹¤.
```

---

ğŸ“Œ 2. CNN ëª¨ë¸ ì •ì˜
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 16 * 16, 128)
        self.fc2 = nn.Linear(128, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 32 * 16 * 16)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
        
ğŸ“Œ **CNNì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ**  
1ï¸âƒ£ `Conv2d` â†’ ì´ë¯¸ì§€ì—ì„œ **íŠ¹ì§•ì„ ì¶”ì¶œ**í•˜ëŠ” í•©ì„±ê³± ê³„ì¸µ  
2ï¸âƒ£ `ReLU` â†’ ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ í‘œí˜„ë ¥ì„ ë†’ì„  
3ï¸âƒ£ `MaxPool2d` â†’ ë‹¤ìš´ìƒ˜í”Œë§ì„ í†µí•´ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê³  íŠ¹ì§•ì„ ë” ìš”ì•½  
4ï¸âƒ£ `Linear` â†’ **ì™„ì „ ì—°ê²°ì¸µ (FC Layer)**, ìµœì¢…ì ì¸ ë¶„ë¥˜ ìˆ˜í–‰

ğŸ‘‰ ì…ë ¥ ì´ë¯¸ì§€ëŠ” **3ì±„ë„(RGB), í¬ê¸° 32x32ë¡œ ê°€ì •**  
ğŸ‘‰ ë§ˆì§€ë§‰ `fc2` ì¸µì—ì„œ **ì¶œë ¥ ë…¸ë“œ ìˆ˜ = 2 (ê°•ì•„ì§€ vs ê³ ì–‘ì´ ë¶„ë¥˜)**
```

ğŸ“Œ 3. ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì •ì˜
```python
import torch.optim as optim

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

ğŸ“Œ **ì†ì‹¤ í•¨ìˆ˜ & ìµœì í™” í•¨ìˆ˜ ì„ íƒ**

- `CrossEntropyLoss()` â†’ **ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œ**ì—ì„œ ì‚¬ìš©
- `Adam` â†’ Adaptive Momentumì„ í™œìš©í•˜ëŠ” **ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜**
- `lr=0.001` â†’ í•™ìŠµë¥  ì„¤ì • (ë„ˆë¬´ í¬ë©´ ë°œì‚°, ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµ ì†ë„ê°€ ëŠë¦¼)

ğŸ‘‰ ëª¨ë¸ì„ **GPU/CPUë¡œ ì´ë™**ì‹œì¼œ í•™ìŠµì„ ì¤€ë¹„í•œë‹¤.
```

---
ğŸ“Œ 4. ëª¨ë¸ í•™ìŠµ ê³¼ì • (Training)
```python
num_epochs = 20
for epoch in range(num_epochs):
    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
    running_loss = 0.0
    
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()  # ê¸°ì¡´ì˜ ê¸°ìš¸ê¸° ì´ˆê¸°í™”

        outputs = model(inputs)  # ìˆœì „íŒŒ (Forward Propagation)
        loss = criterion(outputs, labels)  # ì†ì‹¤ ê³„ì‚°
        loss.backward()  # ì—­ì „íŒŒ (Backward Propagation)
        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")

ğŸ“Œ **ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì • ì •ë¦¬**  
1ï¸âƒ£ **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°** (`train_loader`)  
2ï¸âƒ£ **ìˆœì „íŒŒ(Forward Propagation)**: ì…ë ¥ ë°ì´í„°ë¥¼ CNN ëª¨ë¸ì— í†µê³¼  
3ï¸âƒ£ **ì†ì‹¤(loss) ê³„ì‚°**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ë¼ë²¨ ë¹„êµ  
4ï¸âƒ£ **ì—­ì „íŒŒ(Backward Propagation)**: ì†ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ **ê¸°ìš¸ê¸° ê³„ì‚°**  
5ï¸âƒ£ **ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸** (`optimizer.step()`)  
6ï¸âƒ£ ë°˜ë³µí•˜ì—¬ **ì—í¬í¬(epoch) ë‹¨ìœ„ë¡œ ëª¨ë¸ í•™ìŠµ**

ğŸ‘‰ `print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")`  
ğŸ‘‰ ë§¤ Epochë§ˆë‹¤ í‰ê·  ì†ì‹¤ì„ ì¶œë ¥í•˜ì—¬ í•™ìŠµì´ ì˜ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.
```

---
ğŸ“Œ 5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (Test)
```python
model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
correct = 0
total = 0

with torch.no_grad():  # í‰ê°€ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy: {100 * correct / total:.2f}%")

ğŸ“Œ **ëª¨ë¸ í‰ê°€ ê³¼ì •**  
1ï¸âƒ£ `model.eval()` â†’ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • (BatchNorm, Dropout ë¹„í™œì„±í™”)  
2ï¸âƒ£ `torch.no_grad()` â†’ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•˜ì—¬ **ë©”ëª¨ë¦¬ ì ˆì•½ & ì†ë„ ì¦ê°€**  
3ï¸âƒ£ `torch.max(outputs.data, 1)` â†’ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì„ íƒ  
4ï¸âƒ£ `Accuracy` ê³„ì‚°í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •

ğŸ‘‰ `print(f"Accuracy: {100 * correct / total:.2f}%")`  
ğŸ‘‰ ì •í™•ë„ë¥¼ í¼ì„¼íŠ¸(%) ë‹¨ìœ„ë¡œ ì¶œë ¥í•˜ì—¬ **ìµœì¢… ì„±ëŠ¥ì„ í™•**
```

## ğŸ¯ **ì •ë¦¬**

âœ… CNNì„ í™œìš©í•œ **ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(SimpleCNN) êµ¬í˜„**  
âœ… **ì†ì‹¤ í•¨ìˆ˜(CrossEntropyLoss)ì™€ ìµœì í™” í•¨ìˆ˜(Adam) ì„¤ì •**  
âœ… ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ **ëª¨ë¸ í•™ìŠµ(Training) ì§„í–‰**  
âœ… í•™ìŠµ ì™„ë£Œ í›„ **ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€(Test) ìˆ˜í–‰**

---

## ğŸš€ **ë‹¤ìŒ ë‹¨ê³„**

ì´ì œ ê¸°ë³¸ì ì¸ CNN ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ìµí˜”ë‹¤.  
ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” **ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì•„ë˜ ë°©ë²•ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆë‹¤.**

âœ… **ë°ì´í„° ì¦ê°•(Data Augmentation)**  
âœ… **ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± (ResNet, VGG ë“± í™œìš©)**  
âœ… **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (learning rate, batch size ë“± ì¡°ì •)**

ì´ì œ ì§ì ‘ êµ¬í˜„í•˜ê³ , ëª¨ë¸ì„ ê°œì„ í•´ë³´ì! ğŸ˜†ğŸ”¥  
ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ëŒ“ê¸€ ë‚¨ê²¨ì£¼ì„¸ìš”. ğŸ˜Š