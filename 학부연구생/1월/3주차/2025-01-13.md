# 📌 [React 설치](https://codingapple.com/unit/react1-install-create-react-app-npx/)

```jsx
npm create vite@latest
```

>**node_modules 폴더** : 설치한 라이브러리의 소스코드 보관 폴더
>**public 폴더** : 데이터파일 이미지파일 등 쓸데없는 파일 보관소 (여기 넣으면 나중에 사이트 발행시 원본 보존가능)
>**package.json** : 설치한 라이브러리 기록용 파일
>.config.js** : lint, vite 설정용 파일
>**index.tml** : 메인페이지인데 App.js 내용을 main.js에 넣고 그걸 index.html에 넣는 식으로 짜여져있음

---

# 📌 인코더 - 디코더
###  **Seq2Seq 방식의 한계점과 해결**

- **Seq2Seq 모델의 작동 원리**
    
    - **Encoder**: 입력 시퀀스를 벡터(h4)로 변환. 마지막 벡터(h4)는 이전 입력 정보(h1~h3 포함)를 반영.
    - **Decoder**: 벡터(h4)와 시작 기호(SOS)를 바탕으로 출력 시퀀스를 생성.
- **문제점**
    
    - Encoder의 마지막 벡터(h4)만 디코더로 전달 → 앞선 입력 정보 손실.
    - 고정된 크기의 벡터에 모든 정보를 담기 어려워 성능 저하.

---

###  **Attention 메커니즘**

- **개념**
    
    - Encoder의 모든 hidden state(h0, h1, h2)를 사용.
    - 예측 단어와 관련된 hidden state에 더 큰 가중치를 부여.
    - 예: 'Today'를 예측할 때, '오늘은'의 hidden state(h0)에 더 높은 가중치 부여.
- **가중치 계산**
    
    - Attention Score = Query(hidden state)와 Key(hidden state)의 내적.
    - Score를 Softmax로 확률화 → Value(hidden state)와 곱하여 최종 Attention 출력.

---

###  **Transformer와 Self-Attention**

- **Encoder-Decoder Attention vs. Self-Attention**
    
    - **Encoder-Decoder Attention**: Encoder의 hidden state에 가중치 부여.
    - **Self-Attention**: 입력 시퀀스 단어 간 관계 파악 (Query, Key, Value 사용).
    - Query와 Key의 내적으로 각 단어 간 유사도 계산 후 Softmax로 가중치 산출.
- **Self-Attention의 과정**
    
    1. Query, Key, Value 벡터 계산 (입력 벡터와 가중치 행렬 곱).
    2. Query와 Key의 내적 → Attention Score 계산.
    3. Softmax → 가중치 산출.
    4. Value 벡터에 가중치 곱해 합산 → 최종 출력.

---

###  **Transformer 구조**

- **구성 요소**
    
    - **Multi-Head Attention**: 다양한 관점에서 Attention 계산.
    - **Add & Norm**: Residual Connection + Layer Normalization.
    - **FFN**: ReLU 활성화 함수 사용. 512차원 → 2048차원 → 512차원 변환.
- **Positional Encoding**
    
    - 단어 간 순서 정보를 반영하기 위해 위치 정보를 추가.
    - 임베딩 벡터와 동일한 차원의 벡터(512차원) 사용.

---

###  **Decoder의 Masked Multi-Head Attention**

- 이후 토큰 정보를 사용하지 않도록 마스킹 처리.
- Query, Key 곱의 마스킹 영역에 -∞ 할당 후 Softmax → 0 처리.

---

###  **최종 출력**

- Decoder의 결과 벡터를 Fully Connected Layer에 전달.
- Softmax로 각 단어의 확률 계산 → 가장 높은 확률 단어 선택.

---

#### **1. 디코더 (Decoder)**

**바이너리 디코더(Binary Decoder)**

- 여러 출력선 중 하나를 선택하는 장치.
- **활성화 신호(Enable Signal)**: 디코더를 작동시키는 신호로 주로 `EN'`로 표기.
- **동작 원리**: 입력 신호를 통해 특정 출력만 활성화.

**종류**

1. **Active High Decoder**
    - 선택된 출력은 `1`, 나머지는 `0`.
    - 입력 게이트: AND 게이트.
2. **Active Low Decoder**
    - 선택된 출력은 `0`, 나머지는 `1`.
    - 입력 게이트: NAND 게이트.
3. **활성화 신호가 포함된 디코더**
    - `EN'`이 `0`일 때만 활성화.
    - 출력에 버블이 있으면 Active Low로 동작.

---

#### **2. 인코더 (Encoder)**

**정의**

- 디코더의 반대 동작을 수행.
- 여러 입력 중 하나가 활성화되면 그 입력의 번호를 출력.

**특징**

1. **4입력 인코더의 진리표**
    - 출력 식:
        - `Z0 = A2 + A3`
        - `Z1 = A1 + A3`
2. **추가 출력 (N)**
    - 입력이 모두 `0`인 경우를 구분하기 위해 추가 출력:
        - `N = A0' + A1' + A2' + A3'`
3. **우선순위 인코더**
    - 여러 입력이 동시에 활성화될 경우, **최우선순위** 입력(번호가 큰 입력)만 출력.
    - 
# 💻 참고 
[Transformer 관련 블로그](https://yeong-jin-data-blog.tistory.com/entry/Tranfomer)
[인코더-디코더](https://hunsdev.tistory.com/6)


---


# 야생동물 탐지 및 퇴치 시스템 대시보드 요구사항 명세서 초안 회의

![[31276375-7FA9-46E4-B8CC-0A0E94172669_1_105_c 1.webp]]
###  교수님이 참고하라고 보내주신 이미지

초안작성을 다시 수정하고 개발을 바로 진행할 것


-- | --| 
