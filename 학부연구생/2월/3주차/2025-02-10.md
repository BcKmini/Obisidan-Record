# 📌 [ML](https://wikidocs.net/book/5942)용어 공부
# loss function (손실 함수), cost function (비용 함수)

손실 함수(Loss Function)는 [기계 학습](https://wikidocs.net/120136)과 [딥러닝](https://wikidocs.net/120131)에서 모델의 성능을 측정하는 데 사용되는 함수이다. 이 함수는 모델의 예측값과 실제값 간의 차이를 수치화하여, 모델이 얼마나 잘 또는 못하고 있는지를 나타낸다. 손실 함수의 값이 낮을수록 모델의 성능이 더 좋다고 평가된다. 기계 학습 모델의 학습 과정은 이 손실 함수를 최소화하는 방향으로 진행된다. 손실 함수의 선택은 해결하려는 문제의 유형([회귀](https://wikidocs.net/120111), [분류](https://wikidocs.net/120197), [클러스터링](https://wikidocs.net/120176) 등)에 따라 달라진다.

일반적으로 사용되는 손실 함수에는 [평균 제곱 오차(Mean Squared Error, MSE)](https://wikidocs.net/170549), [교차 엔트로피(Cross-Entropy)](https://wikidocs.net/157190), [힌지 손실(Hinge Loss)](https://en.wikipedia.org/wiki/Hinge_loss) 등이 있다. MSE는 주로 회귀 문제에서 사용되며, 교차 엔트로피는 분류 문제에 자주 사용된다. 손실 함수는 모델의 학습 방향을 결정하는 중요한 요소로, 모델의 목표와 데이터 특성에 적합한 함수를 선택하는 것이 중요하다.

# earning rate (학습률)

학습률(learning rate)은[](https://wikidocs.net/126061#)

 [인공](https://wikidocs.net/126061#) 신경망과 같은 기계 학습 모델이 얼마나 빠르게 학습하는지를 결정하는 [하이퍼파라미터](https://wikidocs.net/120048)이다. 이는 최적화 알고리듬에서 [손실 함수](https://wikidocs.net/120077)의 최소값을 찾아가는 과정에서 각 반복(iteration) 당 이동하는 걸음의 크기를 조정한다. 학습률의 값은 작은 양수로, 너무 높으면 알고리즘이 최소점을 지나치게 되며, 너무 낮으면 수렴하는데 오래 걸리거나 원하지 않는 지역 최소점(local minimum)에 빠질 수 있다.

학습률은 일반적으로 학습 초기에는 높게 설정하여 빠른 학습을 가능하게 하고, 점차 줄여나가는 방식으로 조정된다. 이러한 조정은 학습률 스케줄(learning rate schedule) 또는 적응형 학습률(adaptive learning rate) 방식을 통해 이루어진다. 적응형 학습률은 모델이 데이터를 통해 학습할 때 발생하는 오류를 기반으로 학습률을 동적으로 조정하여, 학습 과정을 최적화한다.

학습률의 적절한 설정은 신경망의 성능을 크게 좌우할 수 있으며, 이는 [스토캐스틱 경사 하강법(Stochastic Gradient Descent, SGD)](https://wikidocs.net/120078)과 같은 최적화 기법에 의해 구현된다. 이러한 기법은 각 데이터 포인트 또는 데이터 배치를 사용하여 모델의 가중치를 업데이트함으로써 학습을 진행한다. 이 과정에서 학습률이 너무 높거나 낮은 경우, 모델이 최적의 학습 결과를 도출하지 못할 위험이 있어, 실험을 통해 최적의 값을 찾는 것이 필요하다.