>터미널 다운

>rsync -avc -e "ssh -p 9922" --progress "sjy@222.116.135.71:/home/sjy/Wild_animal/data/종별_frame90/반달가슴곰/images4"  /Users/gimgyeongmin/Desktop/2024-겨울방학/라벨링/반달슴곰

rsync -avc -e "ssh -p 9922" --progress "sjy@222.116.135.71:/home/sjy/Wild_animal/data/종별_frame90/반달가슴곰/labels4"  /Users/gimgyeongmin/Desktop/2024-겨울방학/라벨링/반달슴곰


반달가슴곰 라벨링 진행 (~2/20)

202p 진행

---
### HAM10000  [캐글](https://www.kaggle.com/code/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy#CNN)
HAM10000 데이터셋을 활용해 피부 병변을 분류하는 딥러닝 모델을 구축했다. 전체 과정은 데이터 로드부터 모델 평가까지 순차적으로 진행했으며, 각각의 단계에서 수행한 작업을 정리해보았다.

---
## 1. 필수 라이브러리 불러오기
먼저 프로젝트에 필요한 라이브러리를 불러왔다. 데이터 처리에는 pandas와 numpy, 시각화에는 matplotlib과 seaborn을 사용했다. 딥러닝 모델을 구성하기 위해 keras와 tensorflow도 함께 불러왔다.
```python
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from glob import glob
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
```

---
## 2. 이미지 데이터 경로 정리
HAM10000 데이터셋은 약 10,000개의 피부 병변 이미지로 구성되어 있다. 이 데이터는 두 개의 폴더(`HAM10000_images_part_1`, `HAM10000_images_part_2`)로 나누어져 있어서 모든 이미지 파일을 한 곳에서 관리할 수 있도록 경로를 정리했다.
```python
base_skin_dir = "/path/to/HAM10000"

imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x 
                     for x in glob(os.path.join(base_skin_dir, 'HAM10000_images_part_*', '*.jpg'))}
```

---
## 3. 데이터 읽기 및 처리
데이터셋에는 `HAM10000_metadata.csv` 파일이 포함되어 있다. 여기에는 각 이미지에 대한 진단 정보(`dx`), 성별(`sex`), 나이(`age`) 등의 정보가 담겨 있다. 이를 pandas를 이용해 읽어왔다.
```python
skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))
skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)
```
데이터를 살펴보면 다음과 같은 컬럼이 포함되어 있다.

|image_id|dx|dx_type|age|sex|localization|
|---|---|---|---|---|---|
|ISIC_0024306|bkl|histo|80|male|scalp|

여기서 `dx`는 피부 병변의 종류를 의미하며, 이 값을 라벨로 사용했다.

---

## 4. 데이터 정리
먼저 결측치와 중복을 확인하고 제거했다.
```python
print(skin_df.isnull().sum())
skin_df.dropna(inplace=True)
# 중복된 데이터 제거
skin_df = skin_df.drop_duplicates()
```

---
## 5. 데이터 분포 분석
데이터셋에서 각 병변 유형(`dx`)이 얼마나 포함되어 있는지 시각화했다.
```python
plt.figure(figsize=(10, 5))
sns.countplot(x='dx', data=skin_df)
plt.xticks(rotation=45)
plt.title("Distribution of Skin Disease Types")
plt.show()
```
확인해보니 병변 유형별로 데이터 개수 차이가 상당히 컸다. 특정 유형의 데이터가 많고, 일부 병변 유형은 데이터가 적었다. 데이터 불균형 문제를 해결하기 위해 이후 `ImageDataGenerator`를 이용해 데이터 증강을 적용했다.

---
## 6. 이미지 불러오기 및 크기 조정
이미지를 모델에 입력하기 위해 **100x100 픽셀** 크기로 조정했다.
```python
def load_and_resize_image(image_path, target_size=(100, 100)):
    return np.array(Image.open(image_path).resize(target_size))

skin_df['image'] = skin_df['path'].map(lambda x: load_and_resize_image(x))
```
이제 데이터프레임(`skin_df`)의 `image` 컬럼에 모든 이미지 데이터가 numpy 배열로 저장되었다.

---
## 7. 학습 데이터와 테스트 데이터 분리
모델을 학습시키기 위해 데이터셋을 **80% 학습 데이터, 20% 테스트 데이터**로 나눴다.
```python
X = np.stack(skin_df['image'].values)
y = skin_df['dx']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---
## 8. 데이터 정규화
이미지 데이터를 신경망이 학습하기 쉽게 정규화했다. 모든 픽셀 값을 `[0,1]` 범위로 변환했다.
```python
X_train = X_train / 255.0
X_test = X_test / 255.0
```

---
## 9. 레이블 인코딩
`dx` 컬럼의 문자열 값을 숫자로 변환해야 신경망에서 사용할 수 있다. 이를 **One-Hot Encoding**으로 변환했다.
```python
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)

y_train = to_categorical(y_train, num_classes=7)
y_test = to_categorical(y_test, num_classes=7)

```

---
## 10. CNN 모델 구성
딥러닝 모델은 **Convolutional Neural Network (CNN)**을 사용했다.
```python
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)),
    MaxPool2D((2,2)),
    BatchNormalization(),
    
    Conv2D(64, (3,3), activation='relu'),
    MaxPool2D((2,2)),
    BatchNormalization(),
    
    Conv2D(128, (3,3), activation='relu'),
    MaxPool2D((2,2)),
    BatchNormalization(),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')
])
```
---
## 11. 모델 학습
Adam 옵티마이저와 categorical cross-entropy 손실 함수를 사용해 모델을 학습했다.
```python
model.compile(optimizer=Adam(learning_rate=0.001), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))
```

---
## 12. 모델 평가
학습이 끝난 후, 테스트 데이터셋에서 성능을 평가했다.
```python
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")
```
혼동 행렬(confusion matrix)을 사용하여 모델의 예측 성능을 시각화
```python
from sklearn.metrics import confusion_matrix

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(cm, annot=True, fmt="d")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

```