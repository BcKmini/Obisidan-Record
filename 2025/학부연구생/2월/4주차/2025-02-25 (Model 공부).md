## 📌 ResNet18
![[Resnet.png]]
- ResNet18은 이미지 인식 등에 사용되는 **딥러닝 모델** 중 하나로, "Residual Network"의 약자

1. **이미지를 이해하는 뇌와 비슷한 구조**
    - 컴퓨터가 이미지를 보고 이해할 때, 여러 단계의 처리를 거쳐 특징을 추출하는데, ResNet18은 이 과정을 여러 "계층"으로 나누어 처리해요.
    - 각 계층은 이미지에서 색깔, 모양, 패턴 같은 정보를 점차적으로 추출합니다.
    
2. **18개의 학습 계층**
    - 이름처럼 ResNet18은 18개의 주요 계층(레이어)을 사용합니다.
    - 이 계층들을 통해 모델은 복잡한 이미지 패턴을 단계적으로 학습해 나갑니다.
    
3. **잔차 연결(Residual Connection)**
    - 딥러닝 모델이 깊어질수록 학습이 어려워지는 "기울기 소실 문제"라는 어려움이 발생하는데, ResNet은 **잔차 연결**이라는 특별한 방법을 사용해 이를 해결해요.
    - 잔차 연결은 마치 "짧은 길"처럼, 정보가 한 계층에서 다른 계층으로 바로 전달되도록 도와줘서, 깊은 모델에서도 학습이 원활하게 이루어지도록 합니다.
    
4. **쉽고 빠른 학습**
    - 이러한 잔차 연결 덕분에 ResNet18은 다른 딥러닝 모델보다 더 빠르고 안정적으로 학습할 수 있습니다.
    - 결과적으로 이미지 분류, 객체 인식 등 다양한 작업에서 좋은 성능을 보입니다.


> ResNet18은 **이미지를 효과적으로 이해하고 분류할 수 있도록 도와주는 똑똑한 컴퓨터 프로그램**인데, 특별한 "지름길" 기능(잔차 연결)을 이용해 많은 정보를 빠르게 처리할 수 있도록 설계된 모델

---
![[densenet121.png]]
## 📌 DenseNet121
- DenseNet121은 이미지 인식 분야에서 사용되는 딥러닝 모델 중 하나로, "Dense Convolutional Network"의 약자

1. **모든 레이어가 서로 연결됨**
    - DenseNet의 가장 큰 특징은 “dense connection”입니다.
    - 즉, 한 레이어의 출력이 다음 레이어뿐만 아니라 그 이후의 모든 레이어로 직접 전달됩니다.
    - 이로 인해 각 레이어는 앞서 나온 여러 정보를 동시에 활용할 수 있게 되어, 학습이 더 원활해집니다.
    
2. **121개의 계층**
    - DenseNet121은 이름 그대로 총 121개의 레이어(계층)로 구성되어 있습니다.
    - 이 많은 레이어들이 함께 작동해 이미지에서 세세한 특징을 추출합니다.
    
3. **효율적인 특징 재사용**
    - DenseNet에서는 이전 레이어에서 학습한 특징을 다음 레이어들이 그대로 받아 사용하기 때문에, 불필요한 중복 학습을 줄일 수 있습니다.
    - 이는 모델의 파라미터 수를 줄이면서도 뛰어난 성능을 발휘할 수 있게 합니다.
    
4. **기울기 소실 문제 완화**
    - DenseNet의 구조 덕분에 정보가 효과적으로 전달되므로, 딥러닝 모델에서 종종 발생하는 기울기 소실 문제(vanishing gradient problem)를 해결하는 데 도움을 줍니다.


> DenseNet121은 각 레이어가 서로 정보를 공유하며, 효율적으로 이미지의 특징을 학습하도록 설계된 딥러닝 모델이다. 

---

찾아 봐야할것
기존에 존재하던 기울기 소실/폭발 문제는 초기 정규화(normalized initialization)와 중간 정규화 층(intermediate normalization layer)을 통해 어느정도 해결됐다.

과적합과 다른 training error을 보이는 degradation이 높은 문제

---
![[mobilenetv2.png]]
## 📌 **MobileNetV2**

- MobileNetV2는 **경량화된 딥러닝 모델**로, 주로 모바일 기기나 리소스가 제한된 환경에서 사용되는 이미지 인식 모델입니다.

1. **효율적인 경량화 모델**
    - MobileNetV2는 **깊이별 분리 합성곱(Depthwise Separable Convolution)**을 사용하여 모델 크기와 계산량을 크게 줄입니다.
    - 이 방식은 **표준 합성곱**보다 더 적은 연산량을 요구하면서도 성능을 유지할 수 있게 해줍니다.
    
2. **인버스 레지듀얼 블록(Inverted Residual Block)**
    - MobileNetV2의 핵심 아이디어 중 하나는 **인버스 레지듀얼 블록**입니다. 이 블록은 기존의 Residual Block을 변형하여, 먼저 차원을 확장하고, 그 후 차원을 축소하는 구조로 구성됩니다.
    - 이 방식은 모델의 파라미터 수를 줄이면서도 효율적으로 특징을 추출할 수 있게 해줍니다.
    
3. **적은 파라미터로 높은 성능**
    - MobileNetV2는 파라미터 수를 크게 줄였음에도 불구하고, **높은 성능**을 발휘할 수 있어, **모바일 디바이스**에서 매우 적합한 모델입니다.
    - 이는 **리소스가 제한적인 환경**에서도 효율적으로 이미지를 분류할 수 있도록 설계된 덕분입니다.
    
4. **배포 환경에서 유리**
    - 모델이 **경량화**되어 있어 모바일 환경에서 빠르게 실행할 수 있으며, **전력 소비도 낮고**, **빠른 응답 속도**를 제공합니다.

> MobileNetV2는 **적은 계산량과 파라미터로도 뛰어난 성능을 발휘**하는 경량화된 딥러닝 모델로, 특히 **모바일 및 임베디드 시스템에서 유리**한 특징을 갖습니다.

---
![[EfficientNet-B0.jpg]]
## 📌 **EfficientNet-B0**

- EfficientNet-B0는 **효율적인 딥러닝 모델**로, 적은 자원으로 높은 성능을 내기 위해 설계된 모델입니다.

1. **복합적 스케일링(Compound Scaling)**
    - EfficientNet-B0는 **복합적 스케일링(compound scaling)** 방법을 사용하여, **네트워크의 깊이, 너비, 해상도**를 균형 있게 확장합니다.
    - 이 방법은 성능을 최적화하기 위해 네트워크 구조의 각 부분을 **동시**에 확장하며, 기존의 단순한 스케일링 방식보다 더 높은 효율을 제공합니다.
    
2. **효율적인 파라미터 사용**
    - EfficientNet-B0는 **적은 파라미터 수**로도 매우 높은 성능을 발휘하는데, 이는 **모델의 크기와 계산량을 최소화**하면서도 뛰어난 예측 성능을 유지할 수 있도록 돕습니다.
    - 이 모델은 **컴퓨터 비전** 분야에서 매우 효과적으로 사용할 수 있습니다.
    
3. **높은 정확도와 빠른 학습**
    - EfficientNet-B0는 **복합적 스케일링** 덕분에 **작은 크기의 모델로도 높은 정확도**를 달성할 수 있으며, 상대적으로 **빠른 학습 속도**를 제공합니다.
    
4. **효율적인 자원 활용**
    - 이 모델은 **저전력 소모**와 **빠른 처리 속도**를 자랑해, **임베디드 시스템**이나 **클라우드 환경**에서도 효율적으로 사용될 수 있습니다.

> EfficientNet-B0는 **복합적 스케일링 기법**을 통해 **적은 파라미터와 높은 효율성**을 구현하며, **고성능 이미지 분류** 모델로 사용됩니다.