## 📌ResNet18
![[Resnet.png]]
- ResNet18은 이미지 인식 등에 사용되는 **딥러닝 모델** 중 하나로, "Residual Network"의 약자

1. **이미지를 이해하는 뇌와 비슷한 구조**
    - 컴퓨터가 이미지를 보고 이해할 때, 여러 단계의 처리를 거쳐 특징을 추출하는데, ResNet18은 이 과정을 여러 "계층"으로 나누어 처리해요.
    - 각 계층은 이미지에서 색깔, 모양, 패턴 같은 정보를 점차적으로 추출합니다.
    
2. **18개의 학습 계층**
    - 이름처럼 ResNet18은 18개의 주요 계층(레이어)을 사용합니다.
    - 이 계층들을 통해 모델은 복잡한 이미지 패턴을 단계적으로 학습해 나갑니다.
    
3. **잔차 연결(Residual Connection)**
    - 딥러닝 모델이 깊어질수록 학습이 어려워지는 "기울기 소실 문제"라는 어려움이 발생하는데, ResNet은 **잔차 연결**이라는 특별한 방법을 사용해 이를 해결해요.
    - 잔차 연결은 마치 "짧은 길"처럼, 정보가 한 계층에서 다른 계층으로 바로 전달되도록 도와줘서, 깊은 모델에서도 학습이 원활하게 이루어지도록 합니다.
    
4. **쉽고 빠른 학습**
    - 이러한 잔차 연결 덕분에 ResNet18은 다른 딥러닝 모델보다 더 빠르고 안정적으로 학습할 수 있습니다.
    - 결과적으로 이미지 분류, 객체 인식 등 다양한 작업에서 좋은 성능을 보입니다.


> ResNet18은 **이미지를 효과적으로 이해하고 분류할 수 있도록 도와주는 똑똑한 컴퓨터 프로그램**인데, 특별한 "지름길" 기능(잔차 연결)을 이용해 많은 정보를 빠르게 처리할 수 있도록 설계된 모델

---
## 📌DenseNet121
- DenseNet121은 이미지 인식 분야에서 사용되는 딥러닝 모델 중 하나로, "Dense Convolutional Network"의 약자

1. **모든 레이어가 서로 연결됨**
    - DenseNet의 가장 큰 특징은 “dense connection”입니다.
    - 즉, 한 레이어의 출력이 다음 레이어뿐만 아니라 그 이후의 모든 레이어로 직접 전달됩니다.
    - 이로 인해 각 레이어는 앞서 나온 여러 정보를 동시에 활용할 수 있게 되어, 학습이 더 원활해집니다.
    
2. **121개의 계층**
    - DenseNet121은 이름 그대로 총 121개의 레이어(계층)로 구성되어 있습니다.
    - 이 많은 레이어들이 함께 작동해 이미지에서 세세한 특징을 추출합니다.
    
3. **효율적인 특징 재사용**
    - DenseNet에서는 이전 레이어에서 학습한 특징을 다음 레이어들이 그대로 받아 사용하기 때문에, 불필요한 중복 학습을 줄일 수 있습니다.
    - 이는 모델의 파라미터 수를 줄이면서도 뛰어난 성능을 발휘할 수 있게 합니다.
    
4. **기울기 소실 문제 완화**
    - DenseNet의 구조 덕분에 정보가 효과적으로 전달되므로, 딥러닝 모델에서 종종 발생하는 기울기 소실 문제(vanishing gradient problem)를 해결하는 데 도움을 줍니다.


> DenseNet121은 각 레이어가 서로 정보를 공유하며, 효율적으로 이미지의 특징을 학습하도록 설계된 딥러닝 모델이다. 

---

찾아 봐야할것
기존에 존재하던 기울기 소실/폭발 문제는 초기 정규화(normalized initialization)와 중간 정규화 층(intermediate normalization layer)을 통해 어느정도 해결됐다.

과적합과 다른 training error을 보이는 degradation이 높은 문제


참고 문헌 : 
https://yhkim4504.tistory.com/3 (-> Resnet 18 논문 리뷰)
https://velog.io/@jaehoon_go/Residual-Learning%EC%9D%98-%EC%9D%B4%ED%95%B4%EC%99%80-ResNet-18-%EA%B5%AC%ED%98%84 (-> Resnet 18 블로그)
https://channelai.tistory.com/2( -> 잔차 연결)
https://wikidocs.net/61375 (-> 기울기 손실, 과적합)
https://sikmulation.tistory.com/50(-> 오버피팅/언더피팅)
https://wkddmswh99.tistory.com/10(train,val,test 나누기)

degradation problem
