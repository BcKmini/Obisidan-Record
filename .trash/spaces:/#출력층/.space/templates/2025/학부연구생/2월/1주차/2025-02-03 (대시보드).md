### 대시보드 작업 변경 사항
![[KakaoTalk_20250202_233428529.png]]
테이블을 제거시키고 하루(24)동안 종(Species)에 빈도 수를 확인 할 수 있는 히스토그램으로 변경


카카오지도api를 사용해서 각 지역에 기기수를 확인 할 수 있게 만듬



---

### 나노 랩 미팅

DB V2.0 라벨링 진행

작업 예정
탐지하던 인원-> 퇴치
윤혁/경민 -> 탐지 부분 파트 예정(?)

### 📌 데이터베이스 증가량 대시보드 구성

**1. 주 단위 데이터 증가량**

- 이번 주 확보된 데이터: **`a` 개**
- 다음 주 예상 데이터: **`b` 개**
- 총 확보된 데이터 대비 증가율 표시

**2. 누적 데이터 현황**

- 현재 총 데이터베이스 크기: **`A` 개**
- 이번 주 대비 증가율: **`(a / A) × 100%`**
- 다음 주 예상 증가율: **`(b / (A + a)) × 100%`**
### **대시보드 주요 지표**

 **주간 데이터 증가량** → 이번 주 추가된 데이터 (`a 개`)  
누적 데이터 총량** → 현재 DB 크기 (`A 개`)  
**주간 성장률** → `(a / A) × 100%`  
**다음 주 예상 증가량** → 다음 주 확보 데이터 (`b 개`)  
**다음 주 예상 DB 성장률** → `(b / (A + a)) × 100%`


## 📌  추가사항

![[bird detection.png]]

- x축 detection_time
- y축 Species
-> 위 버튼을 누르면 종을 선택해서 볼 수 있음
-> 시간당 발견된 종의 빈도수를 나타내는 히스토그램



![[Pasted image 20250203173643.png]]

- [React-kakao-maps-sdk](https://react-kakao-maps-sdk.jaeseokim.dev/) 참고
- 각 지역별 탐지기기 수를 나타내며 마크업을 클릭시 기기에 고유번호를 볼 수 있음

---

# [Dog&Cat 공부]([https://chatgpt.com/share/4ee55e47-8dcf-4d1a-9dbe-b98a452d09cc](https://chatgpt.com/share/4ee55e47-8dcf-4d1a-9dbe-b98a452d09cc)  )

> [DataSet_img 출처](https://www.kaggle.com/search?q=cat+and+dog+classification+in%3Adatasets)

##  📌 1. 데이터 준비

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# 데이터 전처리
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
])

# 데이터셋 다운로드 및 로드
train_data = torchvision.datasets.ImageFolder(root='data/train', transform=transform)
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)

test_data = torchvision.datasets.ImageFolder(root='data/test', transform=transform)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

```

- 데이터셋을 불러오고 전처리하는 부분 
여기에 `torchvision`의 `datasets` 모듈과 `transforms`를 사용하여 데이터를 불러오고 변환을 진행

### 1. `transforms.Resize((64, 64))`를 사용하는 이유

- **입력 이미지 크기 통일:** 신경망은 고정된 크기의 입력을 받도록 설계되므로, 다양한 크기의 원본 이미지를 동일한 크기(64×64)로 변환하여 학습이 가능하도록 한다.
- **메모리 절약:** 너무 큰 이미지를 사용할 경우, 메모리 소모가 커지고 학습 속도가 느려질 수 있다. 64×64 크기는 일반적인 CNN 모델이 처리하기 적절한 크기다.
- **계산량 조절:** 더 큰 이미지를 사용하면 학습 시간이 증가하고, 더 작은 이미지를 사용하면 정보 손실이 발생할 수 있다. 64×64는 적절한 균형
- **다른 크기는 안 쓰나?**
    - 다른 크기도 사용할 수 있다. 예를 들어, **224×224**는 ResNet 같은 대형 모델에서 많이 사용한다.
    - 작은 데이터셋이나 연산량을 줄이고 싶다면 **32×32**도 사용할 수 있다.
    - 최적의 크기는 **데이터셋과 모델에 따라 다르기에 확인 후 진행한다.**.

### 2. `batch_size=32`를 사용하는 이유

- **연산 효율성:**
    - 신경망 학습에서는 한 번에 모든 데이터를 처리하는 대신, 작은 묶음(batch) 단위로 데이터를 입력한다.
    - `batch_size=1`이면 너무 많은 시간이 걸리고, `batch_size`가 너무 크면 메모리 부족 문제가 발생할 수 있다.
- **GPU 활용 최적화:**
    - 대부분의 GPU는 32, 64, 128 같은 2의 거듭제곱(batch size)에 최적화되어 있다.
- **일반적인 선택:**
    - `batch_size=32`는 보편적으로 사용되는 값이며, **메모리 사용량과 학습 속도의 균형이 적절한 값**이다.
    - GPU 메모리가 충분하다면 `batch_size=64` 또는 `batch_size=128`을 사용할 수도 있다.

### 3. `shuffle=True`와 `shuffle=False`를 사용하는 이유

- **`shuffle=True` (훈련 데이터에서 사용)**
    - 학습 데이터는 **랜덤하게 섞어서** 모델이 특정 패턴을 외우지 않도록한다.
    - 데이터의 순서가 고정되면 모델이 학습 데이터 순서에 의존하여 **일반화 성능이 낮아질 가능성**이 있다.
- **`shuffle=False` (테스트 데이터에서 사용)**
    - 테스트 데이터는 모델 성능을 평가하는 용도로 사용되므로, **항상 동일한 순서로 입력하여 일관된 평가**가 가능하도록 한다.
    - 만약 `shuffle=True`로 설정하면, 같은 모델을 여러 번 평가할 때마다 **결과가 달라질 수 있음**.


> 🚀
 - `transforms.Resize((64, 64))`: **입력 크기를 통일하여 CNN 모델이 처리할 수 있도록 하기 위함**.
>  - `batch_size=32`: **연산 효율성과 메모리 사용을 고려하여 적절한 크기**로 설정 (더 크거나 작게 조정 가능).
>  - `shuffle=True (train)`: **훈련 데이터가 랜덤하게 섞이도록 설정**하여 일반화 성능을 향상.
>  - `shuffle=False (test)`: **일관된 평가를 위해 고정된 순서로 데이터 입력**.
>- 